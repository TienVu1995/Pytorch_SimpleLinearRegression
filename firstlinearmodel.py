# -*- coding: utf-8 -*-
"""FirstLinearModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10IGUZTsts89fW3oaXHb-RRNp6CJaDD99
"""

import torch
from torch import nn
import matplotlib.pyplot as plt

torch.__version__

# setup device agnostic code
device='cuda' if  torch.cuda.is_available() else 'cpu'
device

# create some data using linear regression formula of y=weight*X+bias
weight=0.7
bias=0.3

# create range values
start=0
end=1
step=0.02

# create X & y (features & labels)
X=torch.arange(start,end,step).unsqueeze(dim=1)
y=weight*X+bias
X[:10],y[:10]

# split the data
train_split=int(0.8*len(X))
X_train,y_train=X[:train_split],y[:train_split]
X_test,y_test=X[train_split:],y[train_split:]
len(X_train),len(y_train),len(X_test),len(y_test)

#plot the data
def plot_predictions(train_data=X_train,
                     train_labels=y_train,
                     test_data=X_test,
                     test_labels=y_test,
                     predictions=None):
  plt.figure(figsize=(10,7))
  plt.scatter(train_data,train_labels,c='b',label='Training data')
  plt.scatter(test_data,test_labels,c='g',label='Test data')
  if predictions is not None:
    plt.scatter(test_data,predictions,c='r',label='Predictions')
  plt.legend(prop={'size':14});

plot_predictions()

# create module
class LinearRegressionModelV2(nn.Module):
  def __init__(self):
    super().__init__()
    self.linear_layer=nn.Linear(in_features=1,
                                out_features=1)
  def forward(self,x:torch.Tensor)->torch.Tensor:
    return self.linear_layer(x)
#set model
torch.manual_seed(42) 
model_1=LinearRegressionModelV2()
model_1,model_1.state_dict()

# check model current device
next(model_1.parameters()).device

# set model to use target device
model_1.to(device)
next(model_1.parameters()).device

# set data to use target device
X_train=X_train.to(device)
y_train=y_train.to(device)
X_test=X_test.to(device)
y_test=y_test.to(device)

# setup loss function
loss_fn=nn.L1Loss()
# setup optimizer
optimizer=torch.optim.SGD(params=model_1.parameters(),
                          lr=0.01)

# training loop
torch.manual_seed(42)

epochs=200

for epoch in range(epochs):
  model_1.train()
  y_pred=model_1(X_train)
  loss=loss_fn(y_pred,y_train)
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  ## testing
  model_1.eval()
  with torch.inference_mode():
    test_pred=model_1(X_test)
    test_loss=loss_fn(test_pred,y_test)
  #print what happening
  if epoch%10==0:
    print(f"Epoch: {epoch}|Loss:{loss}|Test loss:{test_loss}")

model_1.state_dict()

# making & evaluating predictions
model_1.eval()

with torch.inference_mode():
  y_preds=model_1(X_test)
y_preds

plot_predictions(predictions=y_preds.cpu())

# save & load trained model
from pathlib import Path

MODEL_PATH=Path('models')
MODEL_PATH.mkdir(parents=True,exist_ok=True)

MODEL_NAME='01_pytorch_workflow_model_1.pth'
MODEL_SAVE_PATH= MODEL_PATH / MODEL_NAME

torch.save(obj=model_1.state_dict(),
           f=MODEL_SAVE_PATH)

# load a model
loaded_model_1=LinearRegressionModelV2()
loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))
loaded_model_1.to(device)

loaded_model_1.state_dict()

loaded_model_1.eval()
with torch.inference_mode():
  loaded_model_1_preds=loaded_model_1(X_test)
y_preds==loaded_model_1_preds

